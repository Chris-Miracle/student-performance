{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1EWoZyZuoG6FVe8YkDNccO0GIXkImpAtU",
      "authorship_tag": "ABX9TyMSItJVqFKbrF0I9adjvkAz"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Libraries"
      ],
      "metadata": {
        "id": "XJzgrND3OIp4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P534PxKFN0p1"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load all necessary libraries for prediction objective."
      ],
      "metadata": {
        "id": "en2To7XyOeNi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "4vZwzrNvOoAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect google drive directory\n",
        "os.chdir('/content/drive/MyDrive/Colab/Datasets/')\n",
        "df = pd.read_csv('Student_Performance.csv')\n",
        "\n",
        "# Check for null values\n",
        "df.isnull().sum()\n",
        "\n",
        "# Drop nan values if any\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Remove duplicates\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Run One-hot encoding for Extracurricular Activites\n",
        "df_encoded = pd.get_dummies(df, columns=['Extracurricular Activities'], drop_first=True)\n",
        "\n",
        "# Split data training 80%, test 20%\n",
        "X = df_encoded.drop('Performance Index', axis=1)\n",
        "y = df_encoded['Performance Index']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check sizes\n",
        "print(f'Training set: {X_train.shape}')\n",
        "print(f'Test set: {X_test.shape}')"
      ],
      "metadata": {
        "id": "KbFsjwrKOnPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c753626f-e9cf-4557-8504-64082aec4721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: (7898, 5)\n",
            "Test set: (1975, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load dataset, check for null values, drop nan values, remove duplicates. Convert 'Extracurricular Activities' to categorical data. Split dataset to features and target variable finally split dataset 80% training, 20% test data"
      ],
      "metadata": {
        "id": "CmRgDty3UR5O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "1VwBCvQKU8Ct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network Model"
      ],
      "metadata": {
        "id": "gHbhf1f7bY0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Neural Network regression on train data\n",
        "model = MLPRegressor(hidden_layer_sizes=(10,), max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions_neural = model.predict(X_test)"
      ],
      "metadata": {
        "id": "z4F3NHH6Vnl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The MLPRegressor, takes in key parameters that define its structure and training process.\n",
        "\n",
        "the hidden_layer_sizes gives the number of neurons in the hidden layer, here is it is 10, while the max_iter determines the number of times the model trains iteratively and updates it's weight.\n",
        "\n",
        "Training Process: the input features are fed to the neural network, each neuron adds bias and multiplies the input by weight, calculates the error using backpropagation, it adjusts the weights to minimize the error. it does this iteratively untils the model converges(best weight)"
      ],
      "metadata": {
        "id": "bAL3qMppbjP8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Boosting"
      ],
      "metadata": {
        "id": "pqjcaHBpdynS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Gradient Boosting regression on the train data\n",
        "gb_regressor = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "gb_regressor.fit(X_train, y_train)\n",
        "\n",
        "predictions_gradient = gb_regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "LSx8qEiGdTHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key parameters:\n",
        "\n",
        "n_estimators=100: Specifies the number of decision trees\n",
        "\n",
        "learning_rate=0.1: Controls how much each tree contributes to the final prediction. A lower value makes training more gradual and prevents overfitting.\n",
        "\n",
        "max_depth=3: Defines the depth of each decision tree, limiting how complex each tree can be.\n",
        "\n",
        "random_state=42: Ensures the results are reproducible by controlling the randomness in training.\n",
        "\n",
        "Training Process\n",
        "\n",
        "The model starts with a simple prediction (for example, the average target value).\n",
        "\n",
        "It builds the first decision tree to predict the errors\n",
        "\n",
        "The next tree learns from the previous errors and makes corrections.\n",
        "\n",
        "This process repeats 100 times, with each new tree improving the overall prediction.\n",
        "\n",
        "The final prediction is the sum of all the treesâ€™ outputs, scaled by the learning rate."
      ],
      "metadata": {
        "id": "CZbed7uNfEfP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Metrics"
      ],
      "metadata": {
        "id": "39skjj67fRnX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics on Test Data"
      ],
      "metadata": {
        "id": "B4eB5mjGgkX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the MAE & MSE for both model predictions\n",
        "mae_neural = mean_absolute_error(y_test, predictions_neural)\n",
        "mse_neural = mean_squared_error(y_test, predictions_neural)\n",
        "\n",
        "mae_gradient = mean_absolute_error(y_test, predictions_gradient)\n",
        "mse_gradient = mean_squared_error(y_test, predictions_gradient)\n",
        "\n",
        "print(f'Neural Network - MAE: {mae_neural:.2f}, MSE: {mse_neural:.2f}')\n",
        "print(f'Gradient Boosting - MAE: {mae_gradient:.2f}, MSE: {mse_gradient:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vEtaGNZgKtx",
        "outputId": "928686b3-50bc-4185-9894-11125c04b8a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural Network - MAE: 1.65, MSE: 4.35\n",
            "Gradient Boosting - MAE: 1.70, MSE: 4.58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison and Analysis"
      ],
      "metadata": {
        "id": "oZ406paOhAVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Neural Network (MLPRegressor) performed better on the test set because it has lower MAE and MSE than the Gradient Boosting model.\n",
        "\n",
        "This means the Neural Network made more accurate predictions with smaller overall errors.\n",
        "\n",
        "The difference is not huge, but it suggests that the Neural Network generalizes slightly better."
      ],
      "metadata": {
        "id": "vAFmdoUShE0L"
      }
    }
  ]
}